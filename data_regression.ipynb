{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DICIONÁRIO DE VARIÁVEIS - ENEM 2017\n",
    "\n",
    "## NOME DA VARIÁVEL:\n",
    "\n",
    "### DADOS DO PARTICIPANTE\n",
    "\n",
    "NU_INSCRICAO\n",
    "\n",
    "NU_ANO\n",
    "\n",
    "CO_MUNICIPIO_RESIDENCIA\n",
    "\n",
    "NO_MUNICIPIO_RESIDENCIA\n",
    "\n",
    "CO_UF_RESIDENCIA\n",
    "\n",
    "SG_UF_RESIDENCIA\n",
    "NU_IDADE\n",
    "\n",
    "TP_SEXO\n",
    "\n",
    "TP_ESTADO_CIVIL\n",
    "\n",
    "TP_COR_RACA\n",
    "\n",
    "TP_NACIONALIDADE\n",
    "\n",
    "CO_MUNICIPIO_NASCIMENTO\n",
    "\n",
    "NO_MUNICIPIO_NASCIMENTO\n",
    "\n",
    "CO_UF_NASCIMENTO\n",
    "\n",
    "SG_UF_NASCIMENTO\n",
    "\n",
    "TP_ST_CONCLUSAO\n",
    "\n",
    "TP_ANO_CONCLUIU\n",
    "\n",
    "TP_ESCOLA\n",
    "\n",
    "TP_ENSINO\n",
    "\n",
    "IN_TREINEIRO\n",
    "\n",
    "### DADOS DA ESCOLA:\n",
    "\n",
    "CO_ESCOLA\n",
    "\n",
    "CO_MUNICIPIO_ESC\n",
    "\n",
    "NO_MUNICIPIO_ESC\n",
    "\n",
    "CO_UF_ESC\n",
    "\n",
    "SG_UF_ESC\n",
    "\n",
    "TP_DEPENDENCIA_ADM_ESC\n",
    "\n",
    "TP_LOCALIZACAO_ESC\n",
    "\n",
    "TP_SIT_FUNC_ESC\n",
    "\n",
    "### DADOS DOS PEDIDOS DE ATENDIMENTO ESPECIALIZADO:\n",
    "\n",
    "IN_BAIXA_VISAO\n",
    "\n",
    "IN_CEGUEIRA\n",
    "\n",
    "IN_SURDEZ\n",
    "\n",
    "IN_DEFICIENCIA_AUDITIVA\n",
    "\n",
    "IN_SURDO_CEGUEIRA\n",
    "\n",
    "IN_DEFICIENCIA_FISICA\n",
    "\n",
    "IN_DEFICIENCIA_MENTAL\n",
    "\n",
    "IN_DEFICIT_ATENCAO\n",
    "\n",
    "IN_DISLEXIA\n",
    "\n",
    "IN_DISCALCULIA\n",
    "\n",
    "IN_AUTISMO\n",
    "\n",
    "IN_VISAO_MONOCULAR\n",
    "\n",
    "IN_OUTRA_DEF\n",
    "\n",
    "### DADOS DOS PEDIDOS DE ATENDIMENTO ESPECÍFICO:\n",
    "\n",
    "IN_GESTANTE\n",
    "\n",
    "IN_LACTANTE\n",
    "\n",
    "IN_IDOSO\n",
    "\n",
    "IN_ESTUDA_CLASSE_HOSPITALAR\n",
    "\n",
    "### DADOS DOS PEDIDOS DE RECURSOS ESPECIALIZADOS E ESPECÍFICOS PARA REALIZAÇÃO DAS PROVAS:\n",
    "\n",
    "IN_SEM_RECURSO\n",
    "\n",
    "IN_BRAILLE\n",
    "\n",
    "IN_AMPLIADA_24\n",
    "\n",
    "IN_AMPLIADA_18\n",
    "\n",
    "IN_LEDOR\n",
    "\n",
    "IN_ACESSO\n",
    "\n",
    "IN_TRANSCRICAO\n",
    "\n",
    "IN_LIBRAS\n",
    "\n",
    "IN_LEITURA_LABIAL\n",
    "\n",
    "IN_MESA_CADEIRA_RODAS\n",
    "\n",
    "IN_MESA_CADEIRA_SEPARADA\n",
    "\n",
    "IN_APOIO_PERNA\n",
    "\n",
    "IN_GUIA_INTERPRETE\n",
    "\n",
    "IN_COMPUTADOR\n",
    "\n",
    "IN_CADEIRA_ESPECIAL\n",
    "\n",
    "IN_CADEIRA_CANHOTO\n",
    "\n",
    "IN_CADEIRA_ACOLCHOADA\n",
    "\n",
    "IN_PROVA_DEITADO\n",
    "\n",
    "IN_MOBILIARIO_OBESO\n",
    "\n",
    "IN_LAMINA_OVERLAY\n",
    "\n",
    "IN_PROTETOR_AURICULAR\n",
    "\n",
    "IN_MEDIDOR_GLICOSE\n",
    "\n",
    "IN_MAQUINA_BRAILE\n",
    "\n",
    "IN_SOROBAN\n",
    "\n",
    "IN_MARCA_PASSO\n",
    "\n",
    "IN_SONDA\n",
    "\n",
    "IN_MEDICAMENTOS\n",
    "\n",
    "IN_SALA_INDIVIDUAL\n",
    "\n",
    "IN_SALA_ESPECIAL\n",
    "\n",
    "IN_SALA_ACOMPANHANTE\n",
    "\n",
    "IN_MOBILIARIO_ESPECIFICO\n",
    "\n",
    "IN_MATERIAL_ESPECIFICO\n",
    "\n",
    "IN_NOME_SOCIAL\n",
    "\n",
    "### DADOS DO LOCAL DE APLICAÇÃO DA PROVA:\n",
    "\n",
    "CO_MUNICIPIO_PROVA\n",
    "\n",
    "NO_MUNICIPIO_PROVA\n",
    "\n",
    "CO_UF_PROVA\n",
    "\n",
    "SG_UF_PROVA\n",
    "\n",
    "### DADOS DA PROVA OBJETIVA:\n",
    "\n",
    "TP_PRESENCA_CN\n",
    "\n",
    "\n",
    "TP_PRESENCA_CH\n",
    "\n",
    "\n",
    "TP_PRESENCA_LC\n",
    "\n",
    "\n",
    "TP_PRESENCA_MT\n",
    "\n",
    "CO_PROVA_CN\n",
    "\n",
    "CO_PROVA_CH\n",
    "\n",
    "CO_PROVA_LC\n",
    "\n",
    "CO_PROVA_MT\n",
    "\n",
    "NU_NOTA_CN\n",
    "\n",
    "NU_NOTA_CH\n",
    "\n",
    "NU_NOTA_LC\n",
    "\n",
    "NU_NOTA_MT\n",
    "\n",
    "TX_RESPOSTAS_CN\n",
    "\n",
    "TX_RESPOSTAS_CH\n",
    "\n",
    "TX_RESPOSTAS_LC\n",
    "\n",
    "TX_RESPOSTAS_MT\n",
    "\n",
    "TP_LINGUA\n",
    "\n",
    "TX_GABARITO_CN\n",
    "\n",
    "TX_GABARITO_CH\n",
    "\n",
    "TX_GABARITO_LC\n",
    "\n",
    "TX_GABARITO_MT\n",
    "\n",
    "### DADOS DA REDAÇÃO:\n",
    "\n",
    "TP_STATUS_REDACAO\n",
    "\n",
    "NU_NOTA_COMP1\n",
    "\n",
    "NU_NOTA_COMP2\n",
    "\n",
    "NU_NOTA_COMP3\n",
    "\n",
    "NU_NOTA_COMP4\n",
    "\n",
    "NU_NOTA_COMP5\n",
    "\n",
    "NU_NOTA_REDACAO\n",
    "\n",
    "### DADOS DO QUESTIONÁRIO SOCIOECONÔMICO:\n",
    "\n",
    "Q001\n",
    "\n",
    "Q002\n",
    "\n",
    "Q003\n",
    "\n",
    "Q004\n",
    "\n",
    "Q005\n",
    "\n",
    "Q006\n",
    "\n",
    "Q007\n",
    "\n",
    "Q008\n",
    "\n",
    "Q009\n",
    "\n",
    "Q010\n",
    "\n",
    "Q011\n",
    "\n",
    "Q012\n",
    "\n",
    "Q013\n",
    "\n",
    "Q014\n",
    "\n",
    "Q015\n",
    "\n",
    "Q016\n",
    "\n",
    "Q017\n",
    "\n",
    "Q018\n",
    "\n",
    "Q019\n",
    "\n",
    "Q020\n",
    "\n",
    "Q021\n",
    "\n",
    "Q022\n",
    "\n",
    "Q023\n",
    "\n",
    "Q024\n",
    "\n",
    "Q025\n",
    "\n",
    "Q026\n",
    "\n",
    "Q027\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP_COR_RACA:\n",
    "\n",
    "0 Não declarado\n",
    "\n",
    "1 Branca\n",
    "\n",
    "2 Preta\n",
    "\n",
    "3 Parda\n",
    "\n",
    "4 Amarela\n",
    "\n",
    "5 Indígena\n",
    "\n",
    "TP_ST_CONCLUSAO:\n",
    "\n",
    "1 Já conclui o ensino médio\n",
    "\n",
    "2 Vou concluir o ensino médio em 2017\n",
    "\n",
    "3 Vou concluir o ensino médio após 2017\n",
    "\n",
    "4 Nao concluí e não estou cursando\n",
    "\n",
    "TP_ESCOLA\n",
    "\n",
    "1 Não respondeu\n",
    "\n",
    "2 Pública\n",
    " \n",
    "3 Privada\n",
    "\n",
    "4 Exterior\n",
    "\n",
    "TP_DEPENDENCIA_ADM_ESC\n",
    "\n",
    "1 Federal\n",
    "\n",
    "2 Estadual\n",
    "\n",
    "3 Municipal\n",
    "\n",
    "4 Privada\n",
    "\n",
    "Q001 - até que série seu pai estudou?\n",
    "\n",
    "A - nunca estudo\n",
    "\n",
    "B - Não completou 4 série\n",
    "\n",
    "C - Completou 4 série, mas não 8\n",
    "\n",
    "D - Completou 8 série, mas não o médio\n",
    "\n",
    "E - Completou o médio, mas náo faculdade\n",
    "\n",
    "F - Completou faculdade, mas não pós graduação\n",
    "\n",
    "G - completou pós\n",
    "\n",
    "H - não sei\n",
    "\n",
    "Q002 - até que série sua mãe estudou?\n",
    "\n",
    "A - nunca estudo\n",
    "\n",
    "B - Não completou 4 série\n",
    "\n",
    "C - Completou 4 série, mas não 8\n",
    "\n",
    "D - Completou 8 série, mas não o médio\n",
    "\n",
    "E - Completou o médio, mas náo faculdade\n",
    "\n",
    "F - Completou faculdade, mas não pós graduação\n",
    "\n",
    "G - completou pós\n",
    "\n",
    "H - não sei\n",
    "\n",
    "Q006 - qual é a renda mensal da sua família?\n",
    "\n",
    "A - nenhuma \n",
    "\n",
    "B - até 937\n",
    "\n",
    "C - de 937 a 1405\n",
    "\n",
    "D - de 1045 a 1874\n",
    "\n",
    "E - de 1874 a 2342\n",
    "\n",
    "F - de 2342 ate 2811\n",
    "\n",
    "G - de 2811 ate 3748\n",
    "\n",
    "H - de 3748 ate 4685\n",
    "\n",
    "I - de 4685 ate 5622\n",
    "\n",
    "J - de 5622 ate 6559\n",
    "\n",
    "K - de 6559 ate 7496\n",
    "\n",
    "L - de 7496 ate 8433\n",
    "\n",
    "M - de 8433 ate 9370\n",
    "\n",
    "N - de 9370 ate 11244\n",
    "\n",
    "O - de 11244 ate 14055\n",
    "\n",
    "P - de 14055 ate 18740\n",
    "\n",
    "Q - maior de 18740\n",
    "\n",
    "Q025 - na sua residencia tem acesso a internet?\n",
    "\n",
    "A - Náo\n",
    "\n",
    "B - sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura dos dados\n",
    "data1 = pd.read_csv('MICRODADOS_ENEM_2017.csv', encoding = 'latin1', sep = ';', usecols = ['SG_UF_RESIDENCIA',\n",
    "                                                                                       'NU_IDADE',\n",
    "                                                                                       'TP_SEXO',\n",
    "                                                                                       'TP_COR_RACA',\n",
    "                                                                                       'TP_ST_CONCLUSAO',\n",
    "                                                                                       'TP_ANO_CONCLUIU',\n",
    "                                                                                       'TP_ESCOLA',\n",
    "                                                                                       'TP_DEPENDENCIA_ADM_ESC',\n",
    "                                                                                       'NU_NOTA_CH',\n",
    "                                                                                       'NU_NOTA_CN',\n",
    "                                                                                       'NU_NOTA_LC',\n",
    "                                                                                       'NU_NOTA_LC',\n",
    "                                                                                       'NU_NOTA_MT',\n",
    "                                                                                       'NU_NOTA_REDACAO',\n",
    "                                                                                       'Q001',\n",
    "                                                                                       'Q002',\n",
    "                                                                                       'Q006',\n",
    "                                                                                       'Q025'])\n",
    "#limpeza dos campos NaN\n",
    "data1.dropna(how = 'any', inplace = True, axis = 0)\n",
    "data = data1.copy()\n",
    "#criação do target\n",
    "data['NU_NOTA_MED'] = (data.NU_NOTA_CH + data.NU_NOTA_CN + data.NU_NOTA_LC + data.NU_NOTA_MT + data.NU_NOTA_REDACAO)/5\n",
    "#apgando algumas colunas que não quero\n",
    "data.drop(['NO_MUNICIPIO_RESIDENCIA',\n",
    "           'Q002',\n",
    "           'Q001',\n",
    "           'TP_DEPENDENCIA_ADM_ESC',\n",
    "           'TP_ST_CONCLUSAO',\n",
    "           'NU_NOTA_CN',\n",
    "           'NU_NOTA_CH',\n",
    "           'NU_NOTA_LC',\n",
    "           'NU_NOTA_MT',\n",
    "           'NU_NOTA_REDACAO'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação dos dicionários para mapeamento\n",
    "raca = {0: 'nao_declarado', 1:'branca', 2:'preta', 3:'parda', 4:'amarela', 5:'indigena'}\n",
    "escola = {1: 'nao_respondeu', 2:'publica', 3: 'privado', 4:'exterior'}\n",
    "q006 = {'A':0, 'B':900, 'C':1400, 'D':1900, 'E':2300, 'F':2800, 'G':3700, 'H':4600,\n",
    "       'I':5600, 'J':6600, 'K':7500, 'L':8400, 'M':9400, 'N':12000, 'O':14000, 'P':18700, 'Q':22000}\n",
    "q025 = {'A':'nao', 'B':'sim'}\n",
    "#fazendo o mapeamento\n",
    "data.TP_COR_RACA = data.TP_COR_RACA.map(raca)\n",
    "data.TP_ESCOLA = data.TP_ESCOLA.map(escola)\n",
    "data.Q006 = data.Q006.map(q006)\n",
    "data.Q025 = data.Q025.map(q025)\n",
    "#categorizando os dados (todos serão colunas indivuduais com valores 0 ou 1)\n",
    "data = pd.get_dummies(data, columns=['SG_UF_RESIDENCIA','TP_SEXO','TP_COR_RACA','TP_ESCOLA','Q006','Q025'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o target e tirando o target do dataframe\n",
    "target = data.NU_NOTA_MED\n",
    "data.drop('NU_NOTA_MED', axis = 1, inplace = True)\n",
    "#Fazendo a normalizacao das variaveis independentes e da variavel dependente\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(target).reshape(-1,1))\n",
    "Y = scaler.transform(np.array(target).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rodando o PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(data)\n",
    "data = pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando grupos de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_teste, Y_train, Y_test = train_test_split(data, target , test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3242586785873458"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rodando o modelo linear\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "lm.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32542984607578307"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_teste,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma nova tentativa, dessa vez vou pegar mais colunas dos dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = pd.read_csv('MICRODADOS_ENEM_2017.csv', encoding = 'latin1', sep = ';', usecols = ['SG_UF_RESIDENCIA',\n",
    "'''                                                                                    'NU_IDADE',\n",
    "                                                                                       'TP_SEXO',\n",
    "                                                                                       'TP_COR_RACA',\n",
    "                                                                                       'TP_ST_CONCLUSAO',\n",
    "                                                                                       'TP_ANO_CONCLUIU',\n",
    "                                                                                       'TP_ESCOLA',\n",
    "                                                                                       'IN_TREINEIRO',\n",
    "                                                                                       'TP_DEPENDENCIA_ADM_ESC',\n",
    "                                                                                       'NU_NOTA_CH',\n",
    "                                                                                       'NU_NOTA_CN',\n",
    "                                                                                       'NU_NOTA_LC',\n",
    "                                                                                       'NU_NOTA_LC',\n",
    "                                                                                       'NU_NOTA_MT',\n",
    "                                                                                       'NU_NOTA_REDACAO',\n",
    "                                                                                       'Q001',\n",
    "                                                                                       'Q002',\n",
    "                                                                                       'Q006',\n",
    "                                                                                       'Q024',\n",
    "                                                                                       'Q025']) '''\n",
    "#limpeza dos campos NaN\n",
    "#data1.dropna(how = 'any', inplace = True, axis = 0)\n",
    "data = data1.copy()\n",
    "#criação do target\n",
    "data['NU_NOTA_MED'] = (data.NU_NOTA_CH + data.NU_NOTA_CN + data.NU_NOTA_LC + data.NU_NOTA_MT + data.NU_NOTA_REDACAO)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['NU_NOTA_CH','NU_NOTA_CN','NU_NOTA_LC','NU_NOTA_MT','NU_NOTA_REDACAO'], axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['SG_UF_RESIDENCIA','TP_SEXO','TP_COR_RACA','TP_ST_CONCLUSAO','TP_ESCOLA','TP_DEPENDENCIA_ADM_ESC','Q001','Q002','Q006','Q024','Q025'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o target e tirando o target do dataframe\n",
    "target = data.NU_NOTA_MED\n",
    "data.drop('NU_NOTA_MED', axis = 1, inplace = True)\n",
    "#Fazendo a normalizacao das variaveis independentes e da variavel dependente\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(target).reshape(-1,1))\n",
    "Y = scaler.transform(np.array(target).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(data)\n",
    "data = pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_teste, Y_train, Y_test = train_test_split(data, target , test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3793323136400779"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "lm.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38002087978690213"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_teste, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
