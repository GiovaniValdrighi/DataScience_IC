{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciação Científica - 2019.2 - Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O projeto pode ser dividido em duas etapas principais, cada uma sendo definida pelo banco de dados em que se é utilizado, na primeira utilizados os micro dados do ENEM fornecidos pelo INPE, na segunda etapa utilizaremos uma segunda fonte de dados que contem informações sobre as instituições de ensino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro dados do ENEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os [dados](http://inep.gov.br/microdados) fornecidos pelo INEP são informações de todos os alunos que realizaram o ENEM (Exame Nacional do Ensino Médio) ano a ano, contendo as informações de cadastro do aluno (endereço, necessidade de atendimento especial, questões socioeconômicas) e as notas obtidas nos 5 diferentes testes.\n",
    "\n",
    "Como a quantidade de dados é gigantesca, são cerca de 6 milhões de participantes por ano, para a realização do projeto foi decidido utilizar apenas os dados dos alunos do estado de São Paulo que realizaram a prova em 2017. Iniciando com a seleção e tratamento dos dados para a seguinte utilização de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando os micro dados do ano de 2017, obtivemos 6,731 milhões de linhas, cada um sendo um aluno que realizou a prova e com 137 colunas, cada uma sendo uma informação sobre o aluno. Além dos dados, o INEP oferece um dicionário onde cada coluna possui sua descrição. Para diminuir a quantidade de dados, selecionamos os alunos que fizeram todas as provas, que fizeram no estado de São Paulo e escolhemos as seguintes colunas:\n",
    "- Informações sobre o aplicante (munícipio de residência, idade, sexo, etnia, etc).\n",
    "- Informações sobre a escola em que fez o ensino médio (local, se é pública, dependência adminstrativa, etc).\n",
    "- Informações sobre necessidade de atendimento especial.\n",
    "- Respostas de um questionário socioeconômico do aluno.\n",
    "- Nota média do aluno (é utilizada para a comparação com a previsão do nosso modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os dados são oficiais e obrigatórios para a realização do exame, nesse conjunto de dados não possuimos valores nulos ou não preenchidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nosso objetivo é avaliar quais fatores do aluno são mais importantes e possuem mais influênncia na nota final do aluno (média aritmética da nota dos 5 exames), criamos hipóteses e geramos gráficos para a visualização se de fato existem correlações ou não. Por limitações da biblioteca Altair, cada um dos gráficos utilizou uma amostra aleatória de 2500 linhas de todo o conjunto de dados (cerca de 600 mil linhas).\n",
    "\n",
    "A primeira análise que faremos é análisar se de fato existe aluma relação entre as notas de redação e de matemática, além disso os círculos azuis representam os dados obtidos por participantes do sexo feminino e os quadrados vermelhores representam do sexo masculino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = \"mt_redacao.svg\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = \"mt_redacao.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que apesar de certo ruído, os dados apresentam forte relação direta, alunos que tiraram notas altas em matemática também tiraram nota em redação, e vice-versa.\n",
    "\n",
    "O segundo gráfico que faremos é uma histograma da distribuição dos alunos com base na renda, como os dados já são fornecidos com base em faixas de valor, podemos criar o histograma facilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = \"renda_histo.svg\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = \"renda_histo.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que os dados possuem uma maior concentração nas rendas em torno de R$2000,00 mensais, o que já era esperado visto a distribuição de renda no Brasil. Para uma terceira visualização, iremos combinar o primeiro grafico com o segundo em um gráfico interativo. Abaixo está uma imagem do gráfico obtido, no entanto, a sua versão interativa está diposnível no seguinte [link](https://vega.github.io/editor/#/url/vega-lite/N4KABGBEDGD2B2AzAlgc0gLjMSA3ZApgO6baRHIAmALgBakAsADEwDRS0Fq3WkDMLAL7tIAWwCGAJwDWpHNViwANtWQAHUvACuSpYOHgOceNHG8sAbUMRQEO1Aky5kagE81BUjGSToSzyKwauLQyG6kTAB0fAb2EJAEJrCUyPDoWLZx8XBKsJJy1llQbh5e8LCiqeJKkKyFWZAoBEqUXgAqAAoA+gDKAKIAGgDytfVxkP6oia0ZkHmE8OZQ-oi8IqrU-l49BAAeYABGrmA5eZCCYxCxRZC7BUV2Lu6eWJAAjlrii2FmyLgBl0eTRaXgAcgBVLqgoZtACCXQAsm1Rg94hstq9QbBqOIwJQCGAJNQCKIAIeqUyQQHXBque6op6lV4fL4bX7-FEM4EzKAQqEw+EAJT6ABFYQBhWEjOqo4phDG87G4-FgSQESjiADnAGPYFSHhcsjTHgBnZoEaCqBDOM3+S15FgAdmcJReUFSxMkuGq50NdmNmXsYikslmrq8ByktSgfnUpGoki0BGN8UScBSaXpDVO+Vm3qUSYjBc8KcedzDzy8LO+ONUHJE3K8AEUWAA2aMueVuyCC6bic4ym50jKAtGV5mfGvsgGyyDiVCoNWoMzduBaRach6QE2mBU4SgVcSpUgWNhgABMLAAun6jWNSy5JF8TYg8qITzgUCoCLmyLaLVa8BeP+9qSE6vpXoUfpXoOkAajiWZQFokg1K8PDUGoJoYAA9NhT5EJEqBhLQWgHFoZq+AgxKLJEcCiNhADiyCwN68DIAAatUlCSNwyDYSKZjiD0oRpgQXQAJLithEgmp62HwUJ3QKF0ai5NQtEmrg+pgNckAACQ7pwEheOhmE4dh-zLoRxGkZEzHYYZJLiBZBDLgAtEoYQEBZfCRAwkRRAAVia1ogIIQA/view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = \"renda_mat_red.svg\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = \"renda_mat_red.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que apesar das maiores rendas não estarem tão concentradas nas notas mais altas, as notas mais baixas estão fortemente concentradas nas rendas mais baixas. Ao deslizar o gráfico interativo diagonalmente, podemos ver que conforme subimos para as notas mais altas, a renda se torna menos concentrada nos valores mais baixos. Continuando nesta mesma situação, foi construído uma terceira visualização para estes dados, que pode ser encontrada na versão interativa neste [link](https://vega.github.io/editor/#/url/vega-lite/N4KABGBEDGD2B2AzAlgc0gLjMSA3ZApgO6baRHIAmALgBakAsADEwDRS0Fq3WkDMLAL7tIAWwCGAJwDWpHNViwANtWQAHUvACuSpYOHgokgmoLjeWHHCVbR8UgG1IAOQCqAfWcB5ACoBBdwAlAFEAET8AYT8vSBE3T18AgFkfWKgARRYANkgAXQMISABnU2g5Q0KlcQBPAklHCohsRqaoCRlSSAAjKViWpsgCeDhKZHh0S37WyAAPctaFgepq006ARy1xeFVqc2RcAj7Fxe6xuTFxGa6xotIAJiYC4+mUAiVKc+NTc07rW3tBFMmk9npBqudlqssJANlsdnsDmlIOJUKhjKhzIdoXAtNtIIDniCFpBONwLGAAIwCVhA4pvAjQVQIc5FemM2CSJgUikQlZYqBjah1XDiJRIoYjMaoW5YJxzfJE6YUGj0LAUgAcTH6iuaoPasmhPXqNNBEtgo3G82eUGsHPOIps-Mgxg+Oumc0m1qWfPWm22yF2qkRJq9UGu9ksFyuN3ujxDXsgr3enxMZnJMGU-3xQIgboG4MjkKdsP9gf2hxEKLRBAxQt+sFxvAJxzzJK4qB4pCpbFp1EkWyKiA5okcOBQKjqLLZTIjUFZSgZCk53Pxgly8eJyroXc12sa68akEo5nEVumWkkYuhPGoaiKGAA9A-+0QAHSoAO0LRdLSsyRwbYhmoV84FEB8AHFkFgEV4GQAA1UVKEkbhkAfUITwAZWgQhhgIdwAEkIgfCQiiFSQH2PXYMIABXcBR3DUJRYGA6AilwSBGmbJ5IAAEiKaBOAkTobzvR8HwODF30-b9Xygh9+ME8RxJrcQAFolADAhxL4V8GFfJhXwAKyKZkQEEIA/view), ou logo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"renda_mat_red3.svg\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"renda_mat_red3.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, o próximo objetivo era criar um gráfico do mapa de São Paulo interativo com o gráfico de distribuição de notas (o gráfico que compara notas de matemática e redação), no entanto, após muitas dificuldades para encontrar uma arquivo JSON do mapa de São Paulo que fosse compatível com os nossos dados do ENEM, foi alcançado o seguinte geográfico:\n",
    "(A versão interativa dele está presente no seguinte [link](https://vega.github.io/editor/#/url/vega-lite/N4KABGBEDGD2B2AzAlgc0gLjMSA3ZApgO6baRHIAmALgBakAsADEwDRS0Fq3WkDMLAL7tIAWwCGAJwDWpHNViwANtWQAHUvACuSpYOHgolcdXFzDESFslLSkHtTUBnDAHpXk8UQB0qZHS0AIy0nAkk4eGoCSO84UVcAcWRYXHF4ZAA1cSVKSW5kVwARE3EAZWhCeGgCAH0ASQBhVwknKMlXBTVYACsnBABaJzUAJm9ehEhWCyhEWEkJXiwcRAITawI7VAIep36+AFZ+0S14SahqAE81DaxITp2JwUMDSwkZTe2nWnFrycNIaJwSjIeDoJbTGDKObmCCw85XG5QACOWjSqlMqlwGymcMsKAIOTsADkAKo1IkAeQAKgBBGoAWQAooU-rjzv4lIjIETYKYwKIAJfAszTF6wu6KFTqUgAbWmEHkCLs8FgohB2TOkHxhNuakksGuklUBCc3ng4lE2PZ1E5dgaVHElA2Yrhit+txVavNthE2soxLJlNpDOZmvRttuPL5guFkCecIAus8cedPPAnLN5rLpqA2ZAlIppFoNLr9YbjabzZbWbitfrRDC2UYSo2m1BrLZbg5nG4PF5fP5aEEQmEIlEYnFEslUuksjk8qhaAViqZypVqvUmi02q5jJRYE4agoags1AXqLEnLhIPLYS7a9ICBdiRSGSSiY06gAFOqvgBKjKlHUhSMkSDR1DSNZ5n6TiytygbUnSTIskmbLxnehgJimkAACRONAnASHY3YuO4WKoOIA4BIE3jJK4+GEeIrjkeI-RKP4BDMXw3gMN4TBjH0pwgIIQA/view), no entanto, ela só contem o nome e a média da cidade como informações extras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src = \"mat_plot.svg\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src = \"mat_plot.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O passo seguinte do projeto é o treinamento de modelos em busca da tentativa de predição da nota média do aluno. Com o banco de dados do INEP o modelo que iremos utilizar é a regressão linear. Neste modelo, a nossa previsão **_y_** é uma função linear de **_n_** dimensões, sendo **_n_** o número de variáveis independentes, as informações fornecidas para ser feita a previsão. O treinamento do modelo consiste no cálculo dos coeficientes que diminuem o erro da nossa previsão com os valores objetivos **_y_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"linear_regression.png\" width = \"250px\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"linear_regression.png\" width = \"250px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os dados em dois grupos, parte dos dados serve para o treinamento do modelo (cálculo do parâmetros) e o restante (um quinto dos dados) será utilizado para avaliar a precisão do modelo. Isso é realizado pois, queremos que o modelo funcione de forma geral, e não simplesmente nos dados em que ele foi treinado. Em sequência, precisamos normalizar os dados, isto é, subtrarir de cada coluna sua média e dividir pela variância, pois como as colunas possuem métricas diferentes não queremos que isso influêncie nos coeficientes.\n",
    "\n",
    "Como até dado momento estamos trabalhando com um grande número de características dos alunos, queremos evitar regressões com dados com muitas dimensões. Para isso utilizamos o PCA (análise de componentes principais) para diminuir nossos dados de cerca 120 dimensões para 72 dimensões. Fazemos isso para evitar termos colunas extremamente correlacionadas, o que prejudicaria o cálculo para obter os coeficientes.\n",
    "\n",
    "Por fim treinamos o modelo e verificamos sua precisão com os dados de teste, obtendo um valor R² de 0,47 (o R² é um medida de precisão que varia de 0 a 1, sendo 1 equivalente ao completo acerto das previsões). Abaixo temos o gráfico da comparação entre previsões e notas reais, observe que para uma previsão perfeita, este gráfico seria a reta **_x=y_**, e de fato temos uma aproximação à esta reta, no entanto, em notas mais altas nosso modelo acaba prevendo notas mais baixas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"previsoes_valores.png\"></img>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"previsoes_valores.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão de performance de escolas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta segunda etapa do projeto, utilizamos de 3 fontes de dados diferentes sobre instituições de ensino do estado de São Paulo para prever a performance das mesmas no ENEM do ano de 2015, nessa situação, as escolas foram classificadas em uma pontuação que vai de 0 a 4, sendo 4 a melhor perfórmance. Nosso objetivo será então com base nos dados fornecidos, prever esta classificação. A primeira é uma cartografia digital das escolas do estado de São Paulo com informações sobre o Censo Escolar de 2013 (INEP/MEC), o segundo são dados anuais de 2000 a 2015 contendo informações do número de alunos por ano e as taxas de aprovação dos alunos, por fim, temos mais uma tabela de dados anuais, 1996 a 2015, contendo informações sobre a quantidade de alunos para diversas situações (em cada ano, com necessidades especiais, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente dos dados anteriores, como este conjunto de dados é respondido com menor obrigatoriedade (muitas escolas não possuem todas as informações necessárias, ou não conseguiram responder os questionários por completo) temos um grande número de valores ausentes, e além disso um grande número de valores \"0\". A primeira etapa será lidar com essas ausências.\n",
    "\n",
    "Nos dois conjuntos de dados anuais, como alguns valores não estão ausentes todos os anos (por exemplo, uma escola pode ter fornecido o número de funcionários apenas de 2007 a 2015), realizamos um agrupamento dos dados por ano aplicando a média aritmética dos valores fornecidos, diminuindo consideralmente os valores nulos. Optamos por não utilizar colunas que possuam mais do que 20% de valores ausentes, como estamos tratando com mais de 300 colunas oferecidas, ao final desse processo, permanecemos com 292 colunas.\n",
    "\n",
    "Por fim, em nossa tabela objetivo possuimos o valor de perfórmance de 1243 escolas, dessa forma, para o treinamento dos dados devemos ignorar informações de escolas que não estejam incluidas, terminamos por tanto com 292 colunas e cerca de 1000 linhas.\n",
    "\n",
    "Com esse dados, não iremos realizar análise exploratória. Como as informações quase sempre se assemelham (quantidade de alunos, de funcionários, etc), não iremos avaliar hipóteses através do uso de gráficos e visualizações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciando com uma escolha de variavéis como ocorreu anteriormente, com base no conhecimento prévio sobre escolas, escolhemos informações como:\n",
    "\n",
    "- Número de alunos no 5º ano e no 9º ano\n",
    "- Taxa de abandono\n",
    "- Número de salas\n",
    "- Número de funcionários da escola\n",
    "- Dependência administrativa\n",
    "- Se a escola possui biblioteca, quadra\n",
    "- Valor da escola em teste de avaliação socioeconômica\n",
    "\n",
    "Além disso, aplicamos métodos mais avançados para a escolhas de variáveis, para que o treinamento do modelo não seja afetado pela subjetividade das escolhas de variáveis importantes. Desta forma, aplicamos 3 métodos: recursivo com base nos coeficientes, aplicação de funções avaliadoras e métodos de regularização (Lasso e Ridge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressões e Classificações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os primeiros treinamentos serão realizados com as colunas selecionadas sem o uso de métodos. Da mesma forma que anteriormente, iremos primeiro utilizar do modelo linear. Como os dados não possuem uma intersecção considerável (muitas escolas estão em um, mas não estão em outro), iremos realizar treinamento de dados com as diferentes tabelas e avaliar a sua precisão na previsão. Repetindo o processo de normalizar os dados, realizamos a validação cruzada KFolds, nessa, os dados são divididos em 5 grupos, e repetimos o treinamento 5 vezes, em cada uma das vezes, 1 dos 5 grupos formam os dados de teste e os outros 4 serão os dados de treinamento, dessa forma podemos avaliar como a precisão do modelo varia em casos gerais. Realizando duas regressões com tabelas distintas, obtivemos os resultados:\n",
    "\n",
    "- tabela __\"dados escolares\"__:\n",
    "    - modelo __linear__: R² = 0,409\n",
    "    - modelo __linear__(classes balanceadas): R² = 0,566\n",
    "- tabela __\"esc_rmsp\"__:\n",
    "    - modelo __linear__: R² = 0,501\n",
    "    \n",
    "Obtivemos um R² de 0,56 em um dos nossos teste, valor mais alto que o obtido anteriormente. Prosseguindo, partimos para modelos de classificação, interpretando as notas 0 a 4 como classes, utilizamos o modelo SVM, máquina de vetores de suporte.\n",
    "    \n",
    "  - modelo __SVM__: R² = 0,697\n",
    "  \n",
    "  \n",
    "  \n",
    "    - modelo __SVM__: R² = 0,719\n",
    "    \n",
    "recursivo \n",
    "- tabela __\"dados escolares\"__: R² = 0,445\n",
    "- tabela __\"esc_rmsp\"__: R² = 0,527\n",
    "- tabela __\"rendimento\"__: R² = 0,332\n",
    "- tabela união de __\"dados_escolares\"__ e __\"rendimento\"__: R² = 0,498\n",
    "- tabela união de __\"dados_escolares\"__ e __\"esc_rmsp\"__: R² = 0,434\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
