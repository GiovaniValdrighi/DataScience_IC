{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, mutual_info_classif\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados escolares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (6,8,11,17,18,19,20,111,240) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(692, 210)\n"
     ]
    }
   ],
   "source": [
    "#abrindo os dados\n",
    "dados_escolares = pd.read_csv('DadosEscolares1996-2015.csv', encoding = 'latin1')\n",
    "nota = pd.read_csv('ENEM2015.csv')\n",
    "#agrupando por escolas\n",
    "dados_escolares = dados_escolares.groupby('CODMEC').mean()\n",
    "#Apagando a classe desbalanceada\n",
    "nota = nota[nota.Classificacao != 0]\n",
    "#Em todos Dataframes temos mais escolas do que o nosso target\n",
    "dados_escolares = dados_escolares.reset_index()[dados_escolares.reset_index().CODMEC.isin(nota['CODIGO DA ENTIDADE'])]\n",
    "dados_escolares.drop(dados_escolares.columns[dados_escolares.isnull().mean() != 0], axis=1, inplace = True)\n",
    "#Alterando o nome da coluna para o merge\n",
    "nota.rename(columns = {'CODIGO DA ENTIDADE':'CODMEC'}, inplace = True)\n",
    "#criando o merge com base na coluna CODMEC usando o dataframe target e os dados escolares\n",
    "new_df = pd.merge(dados_escolares, nota, on = 'CODMEC')\n",
    "new_df.drop(['CODMEC', 'ANO','NUMERO DE PARTICIPANTES'], axis = 1, inplace = True)\n",
    "#criando o data e o target\n",
    "data = new_df.drop('Classificacao', axis = 1)\n",
    "target = new_df.Classificacao\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(692, 1)\n",
      "Score: 0.19984315412112058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:299: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\giova\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This SelectKBest instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-e22f45710b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmelhor_score\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmelhor_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmelhores_colunas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\base.py\u001b[0m in \u001b[0;36mget_support\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_support_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scores_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This SelectKBest instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "#Rodando o selectKBest para 12 colunas\n",
    "melhor_score = 0\n",
    "melhores_colunas = []\n",
    "for var in list(range(1,45)):\n",
    "    new_data = SelectKBest(f_regression, k=var).fit_transform(data, target)\n",
    "    print(new_data.shape)\n",
    "    lm = LinearRegression()\n",
    "    scaler = StandardScaler()\n",
    "    data1 = scaler.fit_transform(new_data)\n",
    "    kf = KFold(5, shuffle = True)\n",
    "    r = []\n",
    "    for train_i, test_i in kf.split(data1):\n",
    "        x_train, x_test = data1[train_i], data1[test_i]\n",
    "        y_train, y_test = target[train_i], target[test_i]\n",
    "        lm.fit(x_train, y_train)\n",
    "        r.append(lm.score(x_test, y_test))\n",
    "    print('Score:',sum(r)/5)\n",
    "    if melhor_score < sum(r)/5:\n",
    "        melhor_score = sum(r)/5\n",
    "        melhores_colunas = data.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O melhor score foi:  0\n",
      "Com as seguintes colunas: \n",
      " []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('O melhor score foi: ', melhor_score)\n",
    "print('Com as seguintes colunas: \\n', melhores_colunas)\n",
    "len(melhores_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(692, 1)\n",
      "Score: -0.020735552402415935\n",
      "(692, 2)\n",
      "Score: 0.09254023541263408\n",
      "(692, 3)\n",
      "Score: 0.1026193881515904\n",
      "(692, 4)\n",
      "Score: 0.16287188735837907\n",
      "(692, 5)\n",
      "Score: 0.18902009555531804\n",
      "(692, 6)\n",
      "Score: 0.1870235406078205\n",
      "(692, 7)\n",
      "Score: 0.19416603010637357\n",
      "(692, 8)\n",
      "Score: 0.19122305973507286\n",
      "(692, 9)\n",
      "Score: 0.22864979032541816\n",
      "(692, 10)\n",
      "Score: 0.25606901804429005\n",
      "(692, 11)\n",
      "Score: 0.2463366279572828\n",
      "(692, 12)\n",
      "Score: 0.2593170371026665\n",
      "(692, 13)\n",
      "Score: 0.3613191462251836\n",
      "(692, 14)\n",
      "Score: 0.3769902298212702\n",
      "(692, 15)\n",
      "Score: 0.37843622581775277\n",
      "(692, 16)\n",
      "Score: 0.3495143566311431\n",
      "(692, 17)\n",
      "Score: 0.36167738842125996\n",
      "(692, 18)\n",
      "Score: 0.355156634626521\n",
      "(692, 19)\n",
      "Score: 0.3821195957956733\n",
      "(692, 20)\n",
      "Score: 0.3643143049327343\n",
      "(692, 21)\n",
      "Score: 0.34748959765645693\n",
      "(692, 22)\n",
      "Score: 0.3434253449194958\n",
      "(692, 23)\n",
      "Score: 0.37221647606718083\n",
      "(692, 24)\n",
      "Score: 0.36006140945441995\n",
      "(692, 25)\n",
      "Score: 0.3115527004385297\n",
      "(692, 26)\n",
      "Score: 0.3733318973908431\n",
      "(692, 27)\n",
      "Score: 0.35075678336864724\n",
      "(692, 28)\n",
      "Score: -0.14717569296312216\n",
      "(692, 29)\n",
      "Score: 0.39385593138723163\n",
      "(692, 30)\n",
      "Score: 0.37438456683215304\n",
      "(692, 31)\n",
      "Score: 0.274994925865376\n",
      "(692, 32)\n",
      "Score: 0.34274554972189575\n",
      "(692, 33)\n",
      "Score: 0.3427947472113736\n",
      "(692, 34)\n",
      "Score: 0.4235412336320129\n",
      "(692, 35)\n",
      "Score: 0.4291661705108183\n",
      "(692, 36)\n",
      "Score: 0.41755425972736904\n",
      "(692, 37)\n",
      "Score: 0.41394102496685736\n",
      "(692, 38)\n",
      "Score: 0.41094294073443516\n",
      "(692, 39)\n",
      "Score: 0.37794860096294836\n",
      "(692, 40)\n",
      "Score: 0.41770146121102475\n",
      "(692, 41)\n",
      "Score: 0.39774875440881796\n",
      "(692, 42)\n",
      "Score: 0.4047649795335889\n",
      "(692, 43)\n",
      "Score: 0.39512323706143326\n",
      "(692, 44)\n",
      "Score: 0.42117718514084956\n"
     ]
    }
   ],
   "source": [
    "#Rodando o selectKBest para 12 colunas\n",
    "melhor_score = 0\n",
    "melhores_colunas = []\n",
    "for var in list(range(1,45)):\n",
    "    kbest = SelectKBest(chi2, k = var)\n",
    "    new_data = kbest.fit_transform(data, target)\n",
    "    print(new_data.shape)\n",
    "    lm = LinearRegression()\n",
    "    scaler = StandardScaler()\n",
    "    data1 = scaler.fit_transform(new_data)\n",
    "    kf = KFold(5, shuffle = True)\n",
    "    r = []\n",
    "    for train_i, test_i in kf.split(data1):\n",
    "        x_train, x_test = data1[train_i], data1[test_i]\n",
    "        y_train, y_test = target[train_i], target[test_i]\n",
    "        lm.fit(x_train, y_train)\n",
    "        r.append(lm.score(x_test, y_test))\n",
    "    print('Score:',sum(r)/5)\n",
    "    if melhor_score < sum(r)/5:\n",
    "        melhor_score = sum(r)/5\n",
    "        melhores_colunas = data.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O melhor score foi:  0.4291661705108183\n",
      "Com as seguintes colunas: \n",
      " Index(['Qtde_Docentes', 'NUM_FUNC', 'SETEDU', 'AL_PRE', '5', '6', '6fund',\n",
      "       '0A4', '4A6', '5A6', 'TotalEdInf', 'ALEM1S', 'ALEM2S', 'ALEM3S', 'ALEM',\n",
      "       'ALEF4S', 'ALEF5S', 'ALEF6S', 'ALEF7S', 'ALEF8S', 'ALEF1A4', 'ALEF5A8',\n",
      "       'ALEF1A8', 'ALE9F8S', 'ALE9F9S', 'ALE9F1A5', 'ALE9F6A9', 'ALE9F1A9',\n",
      "       'ALFUNDI', 'ALFUNDII', 'ALFUND', 'ALEJAMED', 'TOTALEJA', 'ALEDPROF',\n",
      "       'TOTAL_ALUNOS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('O melhor score foi: ', melhor_score)\n",
    "print('Com as seguintes colunas: \\n', melhores_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(melhores_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
